{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c05f3f6226042568174e3cddabfa42f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_417a91f38cd24fdaa243fcbb1bcd6615",
              "IPY_MODEL_0de43e8e707e4dcab84aabb6d4f74427",
              "IPY_MODEL_aac8ca7be2d940f595f4b885f47c3a93"
            ],
            "layout": "IPY_MODEL_5fc88c9992df4e33bf51aab166df8556"
          }
        },
        "417a91f38cd24fdaa243fcbb1bcd6615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f21a2cffea1d409c8800417d333868e3",
            "placeholder": "​",
            "style": "IPY_MODEL_373636d86bd24bb5b5a3081da9e54584",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "0de43e8e707e4dcab84aabb6d4f74427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_922aaae484bc4a3f87ebe46f8073de0f",
            "max": 1425814813,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_181219b7856c41db8631ca9c0aa6f85d",
            "value": 1425814813
          }
        },
        "aac8ca7be2d940f595f4b885f47c3a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ad6e526a1ee4de7bdc7c4ac126c14c9",
            "placeholder": "​",
            "style": "IPY_MODEL_09d029a8443e4ea58c48a1e95ae8ae49",
            "value": " 1.43G/1.43G [00:13&lt;00:00, 34.6MB/s]"
          }
        },
        "5fc88c9992df4e33bf51aab166df8556": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f21a2cffea1d409c8800417d333868e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "373636d86bd24bb5b5a3081da9e54584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "922aaae484bc4a3f87ebe46f8073de0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "181219b7856c41db8631ca9c0aa6f85d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ad6e526a1ee4de7bdc7c4ac126c14c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09d029a8443e4ea58c48a1e95ae8ae49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJCg8Nsmk4ZH",
        "outputId": "61f2a791-d2f2-4a0d-db3e-525978ffcf8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E34HP7jDlEWm",
        "outputId": "c92e1c8f-6126-41e4-a459-1656f0edc47a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biWWNkIVlK8P",
        "outputId": "4ff5e8c6-dd68-49f5-c58e-b774d7cd4753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"./Stage_1_Results.csv\", usecols=['pairID1','pairID2','premise','hypothesis','propositional_logic_rule'])"
      ],
      "metadata": {
        "id": "ale_ydw5lRIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaForSequenceClassification, AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli\")"
      ],
      "metadata": {
        "id": "dTNEyN7dltDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in df[\"hypothesis\"]:\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UAT8Po1l5ZR",
        "outputId": "89637af9-d12c-414c-8a94-b156c41c78a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in df[\"premise\"]:\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLoZv_H-q7bE",
        "outputId": "6cc55965-4af2-43d3-9f52-535803822f99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = RobertaForSequenceClassification.from_pretrained(\"ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli\", num_labels=3)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885,
          "referenced_widgets": [
            "6c05f3f6226042568174e3cddabfa42f",
            "417a91f38cd24fdaa243fcbb1bcd6615",
            "0de43e8e707e4dcab84aabb6d4f74427",
            "aac8ca7be2d940f595f4b885f47c3a93",
            "5fc88c9992df4e33bf51aab166df8556",
            "f21a2cffea1d409c8800417d333868e3",
            "373636d86bd24bb5b5a3081da9e54584",
            "922aaae484bc4a3f87ebe46f8073de0f",
            "181219b7856c41db8631ca9c0aa6f85d",
            "5ad6e526a1ee4de7bdc7c4ac126c14c9",
            "09d029a8443e4ea58c48a1e95ae8ae49"
          ]
        },
        "id": "F6LZDEDanJZ4",
        "outputId": "d99e648a-f8ef-47a4-e59a-bb35546bb94e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c05f3f6226042568174e3cddabfa42f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-23): 24 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7v-e-ofgnOPo",
        "outputId": "fc8bffee-fa80-4a32-b815-0cf8dbf198cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids_test_1 = []\n",
        "attention_masks_test_1 = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in df[\"premise\"]:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 200,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids_test_1.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks_test_1.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids_test_1 = torch.cat(input_ids_test_1, dim=0)\n",
        "attention_masks_test_1 = torch.cat(attention_masks_test_1, dim=0)\n",
        "\n",
        "# # Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', df[\"premise\"][0])\n",
        "print('Token IDs:', input_ids_test_1[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQABxxNanTo5",
        "outputId": "3394e40e-3cf6-4a6e-9cc7-72e25b338ae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2622: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  If this church choir sings to the masses as they sing joyous songs from the book at a church, then the church is filled with song. The church is not filled with song.\n",
            "Token IDs: tensor([    0,  1106,    42,  2352, 18558, 22707,     7,     5, 15444,    25,\n",
            "           51,  7884,  5823,  1827,  3686,    31,     5,  1040,    23,    10,\n",
            "         2352,     6,   172,     5,  2352,    16,  3820,    19,  2214,     4,\n",
            "           20,  2352,    16,    45,  3820,    19,  2214,     4,     2,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids_test_2 = []\n",
        "attention_masks_test_2 = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in df[\"hypothesis\"]:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 90,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids_test_2.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks_test_2.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids_test_2 = torch.cat(input_ids_test_2, dim=0)\n",
        "attention_masks_test_2 = torch.cat(attention_masks_test_2, dim=0)\n",
        "\n",
        "# # Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', df[\"hypothesis\"][0])\n",
        "print('Token IDs:', input_ids_test_2[0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSfd-76cvTza",
        "outputId": "76f403e8-6acc-449b-a721-15b937c4909b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  This church choir does not sing to the masses as they sing joyous songs from the book at a church.\n",
            "Token IDs: tensor([    0,   713,  2352, 18558,   473,    45,  7884,     7,     5, 15444,\n",
            "           25,    51,  7884,  5823,  1827,  3686,    31,     5,  1040,    23,\n",
            "           10,  2352,     4,     2,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids_test = torch.cat((input_ids_test_1, input_ids_test_2), dim=1)\n",
        "attention_mask_test = torch.cat((attention_masks_test_1, attention_masks_test_2), dim=1)"
      ],
      "metadata": {
        "id": "BP5vrijvvkHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "labels1 = np.zeros(30312)\n",
        "labels1 = labels1.astype(int)\n",
        "labels1 = torch.tensor(labels1)"
      ],
      "metadata": {
        "id": "orXF9TBOvl8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "prediction_data = TensorDataset(input_ids_test, attention_mask_test, labels1)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "Wnh17SZ9w6Qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids_test)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables\n",
        "predictions , true_labels = [], []\n",
        "i=0\n",
        "# Predict\n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  # Telling the model not to compute or store gradients, saving memory and\n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids,\n",
        "                     token_type_ids=None,\n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  pred_labels = np.argmax(logits, axis=1)\n",
        "  # Store predictions and true labels\n",
        "  predictions.extend(pred_labels.tolist())\n",
        "  i+=32\n",
        "  print(i)\n",
        "print('DONE.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blKr62WZxdhU",
        "outputId": "2a10d96e-f916-4df1-dd58-06495c66c945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 30,312 test sentences...\n",
            "32\n",
            "64\n",
            "96\n",
            "128\n",
            "160\n",
            "192\n",
            "224\n",
            "256\n",
            "288\n",
            "320\n",
            "352\n",
            "384\n",
            "416\n",
            "448\n",
            "480\n",
            "512\n",
            "544\n",
            "576\n",
            "608\n",
            "640\n",
            "672\n",
            "704\n",
            "736\n",
            "768\n",
            "800\n",
            "832\n",
            "864\n",
            "896\n",
            "928\n",
            "960\n",
            "992\n",
            "1024\n",
            "1056\n",
            "1088\n",
            "1120\n",
            "1152\n",
            "1184\n",
            "1216\n",
            "1248\n",
            "1280\n",
            "1312\n",
            "1344\n",
            "1376\n",
            "1408\n",
            "1440\n",
            "1472\n",
            "1504\n",
            "1536\n",
            "1568\n",
            "1600\n",
            "1632\n",
            "1664\n",
            "1696\n",
            "1728\n",
            "1760\n",
            "1792\n",
            "1824\n",
            "1856\n",
            "1888\n",
            "1920\n",
            "1952\n",
            "1984\n",
            "2016\n",
            "2048\n",
            "2080\n",
            "2112\n",
            "2144\n",
            "2176\n",
            "2208\n",
            "2240\n",
            "2272\n",
            "2304\n",
            "2336\n",
            "2368\n",
            "2400\n",
            "2432\n",
            "2464\n",
            "2496\n",
            "2528\n",
            "2560\n",
            "2592\n",
            "2624\n",
            "2656\n",
            "2688\n",
            "2720\n",
            "2752\n",
            "2784\n",
            "2816\n",
            "2848\n",
            "2880\n",
            "2912\n",
            "2944\n",
            "2976\n",
            "3008\n",
            "3040\n",
            "3072\n",
            "3104\n",
            "3136\n",
            "3168\n",
            "3200\n",
            "3232\n",
            "3264\n",
            "3296\n",
            "3328\n",
            "3360\n",
            "3392\n",
            "3424\n",
            "3456\n",
            "3488\n",
            "3520\n",
            "3552\n",
            "3584\n",
            "3616\n",
            "3648\n",
            "3680\n",
            "3712\n",
            "3744\n",
            "3776\n",
            "3808\n",
            "3840\n",
            "3872\n",
            "3904\n",
            "3936\n",
            "3968\n",
            "4000\n",
            "4032\n",
            "4064\n",
            "4096\n",
            "4128\n",
            "4160\n",
            "4192\n",
            "4224\n",
            "4256\n",
            "4288\n",
            "4320\n",
            "4352\n",
            "4384\n",
            "4416\n",
            "4448\n",
            "4480\n",
            "4512\n",
            "4544\n",
            "4576\n",
            "4608\n",
            "4640\n",
            "4672\n",
            "4704\n",
            "4736\n",
            "4768\n",
            "4800\n",
            "4832\n",
            "4864\n",
            "4896\n",
            "4928\n",
            "4960\n",
            "4992\n",
            "5024\n",
            "5056\n",
            "5088\n",
            "5120\n",
            "5152\n",
            "5184\n",
            "5216\n",
            "5248\n",
            "5280\n",
            "5312\n",
            "5344\n",
            "5376\n",
            "5408\n",
            "5440\n",
            "5472\n",
            "5504\n",
            "5536\n",
            "5568\n",
            "5600\n",
            "5632\n",
            "5664\n",
            "5696\n",
            "5728\n",
            "5760\n",
            "5792\n",
            "5824\n",
            "5856\n",
            "5888\n",
            "5920\n",
            "5952\n",
            "5984\n",
            "6016\n",
            "6048\n",
            "6080\n",
            "6112\n",
            "6144\n",
            "6176\n",
            "6208\n",
            "6240\n",
            "6272\n",
            "6304\n",
            "6336\n",
            "6368\n",
            "6400\n",
            "6432\n",
            "6464\n",
            "6496\n",
            "6528\n",
            "6560\n",
            "6592\n",
            "6624\n",
            "6656\n",
            "6688\n",
            "6720\n",
            "6752\n",
            "6784\n",
            "6816\n",
            "6848\n",
            "6880\n",
            "6912\n",
            "6944\n",
            "6976\n",
            "7008\n",
            "7040\n",
            "7072\n",
            "7104\n",
            "7136\n",
            "7168\n",
            "7200\n",
            "7232\n",
            "7264\n",
            "7296\n",
            "7328\n",
            "7360\n",
            "7392\n",
            "7424\n",
            "7456\n",
            "7488\n",
            "7520\n",
            "7552\n",
            "7584\n",
            "7616\n",
            "7648\n",
            "7680\n",
            "7712\n",
            "7744\n",
            "7776\n",
            "7808\n",
            "7840\n",
            "7872\n",
            "7904\n",
            "7936\n",
            "7968\n",
            "8000\n",
            "8032\n",
            "8064\n",
            "8096\n",
            "8128\n",
            "8160\n",
            "8192\n",
            "8224\n",
            "8256\n",
            "8288\n",
            "8320\n",
            "8352\n",
            "8384\n",
            "8416\n",
            "8448\n",
            "8480\n",
            "8512\n",
            "8544\n",
            "8576\n",
            "8608\n",
            "8640\n",
            "8672\n",
            "8704\n",
            "8736\n",
            "8768\n",
            "8800\n",
            "8832\n",
            "8864\n",
            "8896\n",
            "8928\n",
            "8960\n",
            "8992\n",
            "9024\n",
            "9056\n",
            "9088\n",
            "9120\n",
            "9152\n",
            "9184\n",
            "9216\n",
            "9248\n",
            "9280\n",
            "9312\n",
            "9344\n",
            "9376\n",
            "9408\n",
            "9440\n",
            "9472\n",
            "9504\n",
            "9536\n",
            "9568\n",
            "9600\n",
            "9632\n",
            "9664\n",
            "9696\n",
            "9728\n",
            "9760\n",
            "9792\n",
            "9824\n",
            "9856\n",
            "9888\n",
            "9920\n",
            "9952\n",
            "9984\n",
            "10016\n",
            "10048\n",
            "10080\n",
            "10112\n",
            "10144\n",
            "10176\n",
            "10208\n",
            "10240\n",
            "10272\n",
            "10304\n",
            "10336\n",
            "10368\n",
            "10400\n",
            "10432\n",
            "10464\n",
            "10496\n",
            "10528\n",
            "10560\n",
            "10592\n",
            "10624\n",
            "10656\n",
            "10688\n",
            "10720\n",
            "10752\n",
            "10784\n",
            "10816\n",
            "10848\n",
            "10880\n",
            "10912\n",
            "10944\n",
            "10976\n",
            "11008\n",
            "11040\n",
            "11072\n",
            "11104\n",
            "11136\n",
            "11168\n",
            "11200\n",
            "11232\n",
            "11264\n",
            "11296\n",
            "11328\n",
            "11360\n",
            "11392\n",
            "11424\n",
            "11456\n",
            "11488\n",
            "11520\n",
            "11552\n",
            "11584\n",
            "11616\n",
            "11648\n",
            "11680\n",
            "11712\n",
            "11744\n",
            "11776\n",
            "11808\n",
            "11840\n",
            "11872\n",
            "11904\n",
            "11936\n",
            "11968\n",
            "12000\n",
            "12032\n",
            "12064\n",
            "12096\n",
            "12128\n",
            "12160\n",
            "12192\n",
            "12224\n",
            "12256\n",
            "12288\n",
            "12320\n",
            "12352\n",
            "12384\n",
            "12416\n",
            "12448\n",
            "12480\n",
            "12512\n",
            "12544\n",
            "12576\n",
            "12608\n",
            "12640\n",
            "12672\n",
            "12704\n",
            "12736\n",
            "12768\n",
            "12800\n",
            "12832\n",
            "12864\n",
            "12896\n",
            "12928\n",
            "12960\n",
            "12992\n",
            "13024\n",
            "13056\n",
            "13088\n",
            "13120\n",
            "13152\n",
            "13184\n",
            "13216\n",
            "13248\n",
            "13280\n",
            "13312\n",
            "13344\n",
            "13376\n",
            "13408\n",
            "13440\n",
            "13472\n",
            "13504\n",
            "13536\n",
            "13568\n",
            "13600\n",
            "13632\n",
            "13664\n",
            "13696\n",
            "13728\n",
            "13760\n",
            "13792\n",
            "13824\n",
            "13856\n",
            "13888\n",
            "13920\n",
            "13952\n",
            "13984\n",
            "14016\n",
            "14048\n",
            "14080\n",
            "14112\n",
            "14144\n",
            "14176\n",
            "14208\n",
            "14240\n",
            "14272\n",
            "14304\n",
            "14336\n",
            "14368\n",
            "14400\n",
            "14432\n",
            "14464\n",
            "14496\n",
            "14528\n",
            "14560\n",
            "14592\n",
            "14624\n",
            "14656\n",
            "14688\n",
            "14720\n",
            "14752\n",
            "14784\n",
            "14816\n",
            "14848\n",
            "14880\n",
            "14912\n",
            "14944\n",
            "14976\n",
            "15008\n",
            "15040\n",
            "15072\n",
            "15104\n",
            "15136\n",
            "15168\n",
            "15200\n",
            "15232\n",
            "15264\n",
            "15296\n",
            "15328\n",
            "15360\n",
            "15392\n",
            "15424\n",
            "15456\n",
            "15488\n",
            "15520\n",
            "15552\n",
            "15584\n",
            "15616\n",
            "15648\n",
            "15680\n",
            "15712\n",
            "15744\n",
            "15776\n",
            "15808\n",
            "15840\n",
            "15872\n",
            "15904\n",
            "15936\n",
            "15968\n",
            "16000\n",
            "16032\n",
            "16064\n",
            "16096\n",
            "16128\n",
            "16160\n",
            "16192\n",
            "16224\n",
            "16256\n",
            "16288\n",
            "16320\n",
            "16352\n",
            "16384\n",
            "16416\n",
            "16448\n",
            "16480\n",
            "16512\n",
            "16544\n",
            "16576\n",
            "16608\n",
            "16640\n",
            "16672\n",
            "16704\n",
            "16736\n",
            "16768\n",
            "16800\n",
            "16832\n",
            "16864\n",
            "16896\n",
            "16928\n",
            "16960\n",
            "16992\n",
            "17024\n",
            "17056\n",
            "17088\n",
            "17120\n",
            "17152\n",
            "17184\n",
            "17216\n",
            "17248\n",
            "17280\n",
            "17312\n",
            "17344\n",
            "17376\n",
            "17408\n",
            "17440\n",
            "17472\n",
            "17504\n",
            "17536\n",
            "17568\n",
            "17600\n",
            "17632\n",
            "17664\n",
            "17696\n",
            "17728\n",
            "17760\n",
            "17792\n",
            "17824\n",
            "17856\n",
            "17888\n",
            "17920\n",
            "17952\n",
            "17984\n",
            "18016\n",
            "18048\n",
            "18080\n",
            "18112\n",
            "18144\n",
            "18176\n",
            "18208\n",
            "18240\n",
            "18272\n",
            "18304\n",
            "18336\n",
            "18368\n",
            "18400\n",
            "18432\n",
            "18464\n",
            "18496\n",
            "18528\n",
            "18560\n",
            "18592\n",
            "18624\n",
            "18656\n",
            "18688\n",
            "18720\n",
            "18752\n",
            "18784\n",
            "18816\n",
            "18848\n",
            "18880\n",
            "18912\n",
            "18944\n",
            "18976\n",
            "19008\n",
            "19040\n",
            "19072\n",
            "19104\n",
            "19136\n",
            "19168\n",
            "19200\n",
            "19232\n",
            "19264\n",
            "19296\n",
            "19328\n",
            "19360\n",
            "19392\n",
            "19424\n",
            "19456\n",
            "19488\n",
            "19520\n",
            "19552\n",
            "19584\n",
            "19616\n",
            "19648\n",
            "19680\n",
            "19712\n",
            "19744\n",
            "19776\n",
            "19808\n",
            "19840\n",
            "19872\n",
            "19904\n",
            "19936\n",
            "19968\n",
            "20000\n",
            "20032\n",
            "20064\n",
            "20096\n",
            "20128\n",
            "20160\n",
            "20192\n",
            "20224\n",
            "20256\n",
            "20288\n",
            "20320\n",
            "20352\n",
            "20384\n",
            "20416\n",
            "20448\n",
            "20480\n",
            "20512\n",
            "20544\n",
            "20576\n",
            "20608\n",
            "20640\n",
            "20672\n",
            "20704\n",
            "20736\n",
            "20768\n",
            "20800\n",
            "20832\n",
            "20864\n",
            "20896\n",
            "20928\n",
            "20960\n",
            "20992\n",
            "21024\n",
            "21056\n",
            "21088\n",
            "21120\n",
            "21152\n",
            "21184\n",
            "21216\n",
            "21248\n",
            "21280\n",
            "21312\n",
            "21344\n",
            "21376\n",
            "21408\n",
            "21440\n",
            "21472\n",
            "21504\n",
            "21536\n",
            "21568\n",
            "21600\n",
            "21632\n",
            "21664\n",
            "21696\n",
            "21728\n",
            "21760\n",
            "21792\n",
            "21824\n",
            "21856\n",
            "21888\n",
            "21920\n",
            "21952\n",
            "21984\n",
            "22016\n",
            "22048\n",
            "22080\n",
            "22112\n",
            "22144\n",
            "22176\n",
            "22208\n",
            "22240\n",
            "22272\n",
            "22304\n",
            "22336\n",
            "22368\n",
            "22400\n",
            "22432\n",
            "22464\n",
            "22496\n",
            "22528\n",
            "22560\n",
            "22592\n",
            "22624\n",
            "22656\n",
            "22688\n",
            "22720\n",
            "22752\n",
            "22784\n",
            "22816\n",
            "22848\n",
            "22880\n",
            "22912\n",
            "22944\n",
            "22976\n",
            "23008\n",
            "23040\n",
            "23072\n",
            "23104\n",
            "23136\n",
            "23168\n",
            "23200\n",
            "23232\n",
            "23264\n",
            "23296\n",
            "23328\n",
            "23360\n",
            "23392\n",
            "23424\n",
            "23456\n",
            "23488\n",
            "23520\n",
            "23552\n",
            "23584\n",
            "23616\n",
            "23648\n",
            "23680\n",
            "23712\n",
            "23744\n",
            "23776\n",
            "23808\n",
            "23840\n",
            "23872\n",
            "23904\n",
            "23936\n",
            "23968\n",
            "24000\n",
            "24032\n",
            "24064\n",
            "24096\n",
            "24128\n",
            "24160\n",
            "24192\n",
            "24224\n",
            "24256\n",
            "24288\n",
            "24320\n",
            "24352\n",
            "24384\n",
            "24416\n",
            "24448\n",
            "24480\n",
            "24512\n",
            "24544\n",
            "24576\n",
            "24608\n",
            "24640\n",
            "24672\n",
            "24704\n",
            "24736\n",
            "24768\n",
            "24800\n",
            "24832\n",
            "24864\n",
            "24896\n",
            "24928\n",
            "24960\n",
            "24992\n",
            "25024\n",
            "25056\n",
            "25088\n",
            "25120\n",
            "25152\n",
            "25184\n",
            "25216\n",
            "25248\n",
            "25280\n",
            "25312\n",
            "25344\n",
            "25376\n",
            "25408\n",
            "25440\n",
            "25472\n",
            "25504\n",
            "25536\n",
            "25568\n",
            "25600\n",
            "25632\n",
            "25664\n",
            "25696\n",
            "25728\n",
            "25760\n",
            "25792\n",
            "25824\n",
            "25856\n",
            "25888\n",
            "25920\n",
            "25952\n",
            "25984\n",
            "26016\n",
            "26048\n",
            "26080\n",
            "26112\n",
            "26144\n",
            "26176\n",
            "26208\n",
            "26240\n",
            "26272\n",
            "26304\n",
            "26336\n",
            "26368\n",
            "26400\n",
            "26432\n",
            "26464\n",
            "26496\n",
            "26528\n",
            "26560\n",
            "26592\n",
            "26624\n",
            "26656\n",
            "26688\n",
            "26720\n",
            "26752\n",
            "26784\n",
            "26816\n",
            "26848\n",
            "26880\n",
            "26912\n",
            "26944\n",
            "26976\n",
            "27008\n",
            "27040\n",
            "27072\n",
            "27104\n",
            "27136\n",
            "27168\n",
            "27200\n",
            "27232\n",
            "27264\n",
            "27296\n",
            "27328\n",
            "27360\n",
            "27392\n",
            "27424\n",
            "27456\n",
            "27488\n",
            "27520\n",
            "27552\n",
            "27584\n",
            "27616\n",
            "27648\n",
            "27680\n",
            "27712\n",
            "27744\n",
            "27776\n",
            "27808\n",
            "27840\n",
            "27872\n",
            "27904\n",
            "27936\n",
            "27968\n",
            "28000\n",
            "28032\n",
            "28064\n",
            "28096\n",
            "28128\n",
            "28160\n",
            "28192\n",
            "28224\n",
            "28256\n",
            "28288\n",
            "28320\n",
            "28352\n",
            "28384\n",
            "28416\n",
            "28448\n",
            "28480\n",
            "28512\n",
            "28544\n",
            "28576\n",
            "28608\n",
            "28640\n",
            "28672\n",
            "28704\n",
            "28736\n",
            "28768\n",
            "28800\n",
            "28832\n",
            "28864\n",
            "28896\n",
            "28928\n",
            "28960\n",
            "28992\n",
            "29024\n",
            "29056\n",
            "29088\n",
            "29120\n",
            "29152\n",
            "29184\n",
            "29216\n",
            "29248\n",
            "29280\n",
            "29312\n",
            "29344\n",
            "29376\n",
            "29408\n",
            "29440\n",
            "29472\n",
            "29504\n",
            "29536\n",
            "29568\n",
            "29600\n",
            "29632\n",
            "29664\n",
            "29696\n",
            "29728\n",
            "29760\n",
            "29792\n",
            "29824\n",
            "29856\n",
            "29888\n",
            "29920\n",
            "29952\n",
            "29984\n",
            "30016\n",
            "30048\n",
            "30080\n",
            "30112\n",
            "30144\n",
            "30176\n",
            "30208\n",
            "30240\n",
            "30272\n",
            "30304\n",
            "30336\n",
            "DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label = []\n",
        "for i in predictions:\n",
        "  if i==0:\n",
        "    label.append(\"entailment\")\n",
        "  elif i==1:\n",
        "    label.append(\"contradiction\")\n",
        "  else:\n",
        "    label.append(\"neutral\")"
      ],
      "metadata": {
        "id": "1kSyVdkjCNBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "new_series = pd.Series(label, name='Predicted Labels')\n",
        "df_test = pd.concat([df, new_series], axis=1)"
      ],
      "metadata": {
        "id": "b8GYK5qsORXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        },
        "id": "VApYiIMhOqcs",
        "outputId": "614af321-280e-482e-c0d2-923647827808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   pairID1             pairID2  \\\n",
              "0      2677109430.jpg#1r1e                 NaN   \n",
              "1      2677109430.jpg#1r1e                 NaN   \n",
              "2      2677109430.jpg#1r1e                 NaN   \n",
              "3      2677109430.jpg#1r1e                 NaN   \n",
              "4      2677109430.jpg#1r1e                 NaN   \n",
              "...                    ...                 ...   \n",
              "30307  4378810163.jpg#4r1e  152881593.jpg#1r1e   \n",
              "30308  4378810163.jpg#4r1e  152881593.jpg#1r1e   \n",
              "30309  2677109430.jpg#1r1e  152881593.jpg#1r1e   \n",
              "30310  2677109430.jpg#1r1e  152881593.jpg#1r1e   \n",
              "30311  2677109430.jpg#1r1e  152881593.jpg#1r1e   \n",
              "\n",
              "                                                 premise  \\\n",
              "0      If this church choir sings to the masses as th...   \n",
              "1      If this church choir sings to the masses as th...   \n",
              "2      If the church is not filled with song, then th...   \n",
              "3      If this church choir sings to the masses as th...   \n",
              "4      Either this church choir does not sing to the ...   \n",
              "...                                                  ...   \n",
              "30307  If two women are observing something together,...   \n",
              "30308  If two women are observing something together,...   \n",
              "30309  If this church choir sings to the masses as th...   \n",
              "30310  If this church choir sings to the masses as th...   \n",
              "30311  If this church choir sings to the masses as th...   \n",
              "\n",
              "                                              hypothesis  \\\n",
              "0      This church choir does not sing to the masses ...   \n",
              "1      If the church is not filled with song, then th...   \n",
              "2      If this church choir sings to the masses as th...   \n",
              "3      Either this church choir does not sing to the ...   \n",
              "4      If this church choir sings to the masses as th...   \n",
              "...                                                  ...   \n",
              "30307  Either no two women are observing something to...   \n",
              "30308  Either two girls are looking at something or n...   \n",
              "30309  Either the church is filled with song or a man...   \n",
              "30310  Either this church choir does not sing to the ...   \n",
              "30311  Either the church is filled with song or no ma...   \n",
              "\n",
              "      propositional_logic_rule Predicted Labels  \n",
              "0                Modus Tollens          neutral  \n",
              "1             Transportation 1    contradiction  \n",
              "2             Transportation 2       entailment  \n",
              "3       Material Implication 1          neutral  \n",
              "4       Material Implication 2          neutral  \n",
              "...                        ...              ...  \n",
              "30307      Destructive Dilemma       entailment  \n",
              "30308    Bidirectional Dilemma       entailment  \n",
              "30309     Constructive Dilemma       entailment  \n",
              "30310      Destructive Dilemma       entailment  \n",
              "30311    Bidirectional Dilemma          neutral  \n",
              "\n",
              "[30312 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8b0d7e5-2621-4d82-b374-2fde1d3d64e6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pairID1</th>\n",
              "      <th>pairID2</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>propositional_logic_rule</th>\n",
              "      <th>Predicted Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2677109430.jpg#1r1e</td>\n",
              "      <td>NaN</td>\n",
              "      <td>If this church choir sings to the masses as th...</td>\n",
              "      <td>This church choir does not sing to the masses ...</td>\n",
              "      <td>Modus Tollens</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2677109430.jpg#1r1e</td>\n",
              "      <td>NaN</td>\n",
              "      <td>If this church choir sings to the masses as th...</td>\n",
              "      <td>If the church is not filled with song, then th...</td>\n",
              "      <td>Transportation 1</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2677109430.jpg#1r1e</td>\n",
              "      <td>NaN</td>\n",
              "      <td>If the church is not filled with song, then th...</td>\n",
              "      <td>If this church choir sings to the masses as th...</td>\n",
              "      <td>Transportation 2</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2677109430.jpg#1r1e</td>\n",
              "      <td>NaN</td>\n",
              "      <td>If this church choir sings to the masses as th...</td>\n",
              "      <td>Either this church choir does not sing to the ...</td>\n",
              "      <td>Material Implication 1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2677109430.jpg#1r1e</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Either this church choir does not sing to the ...</td>\n",
              "      <td>If this church choir sings to the masses as th...</td>\n",
              "      <td>Material Implication 2</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30307</th>\n",
              "      <td>4378810163.jpg#4r1e</td>\n",
              "      <td>152881593.jpg#1r1e</td>\n",
              "      <td>If two women are observing something together,...</td>\n",
              "      <td>Either no two women are observing something to...</td>\n",
              "      <td>Destructive Dilemma</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30308</th>\n",
              "      <td>4378810163.jpg#4r1e</td>\n",
              "      <td>152881593.jpg#1r1e</td>\n",
              "      <td>If two women are observing something together,...</td>\n",
              "      <td>Either two girls are looking at something or n...</td>\n",
              "      <td>Bidirectional Dilemma</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30309</th>\n",
              "      <td>2677109430.jpg#1r1e</td>\n",
              "      <td>152881593.jpg#1r1e</td>\n",
              "      <td>If this church choir sings to the masses as th...</td>\n",
              "      <td>Either the church is filled with song or a man...</td>\n",
              "      <td>Constructive Dilemma</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30310</th>\n",
              "      <td>2677109430.jpg#1r1e</td>\n",
              "      <td>152881593.jpg#1r1e</td>\n",
              "      <td>If this church choir sings to the masses as th...</td>\n",
              "      <td>Either this church choir does not sing to the ...</td>\n",
              "      <td>Destructive Dilemma</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30311</th>\n",
              "      <td>2677109430.jpg#1r1e</td>\n",
              "      <td>152881593.jpg#1r1e</td>\n",
              "      <td>If this church choir sings to the masses as th...</td>\n",
              "      <td>Either the church is filled with song or no ma...</td>\n",
              "      <td>Bidirectional Dilemma</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30312 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8b0d7e5-2621-4d82-b374-2fde1d3d64e6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b8b0d7e5-2621-4d82-b374-2fde1d3d64e6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b8b0d7e5-2621-4d82-b374-2fde1d3d64e6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-12c19ee5-603c-42c2-a1d0-2892095a9166\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-12c19ee5-603c-42c2-a1d0-2892095a9166')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-12c19ee5-603c-42c2-a1d0-2892095a9166 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.to_csv('Stage_2_RoBERTA_Multi_Task_Results.csv')"
      ],
      "metadata": {
        "id": "UvtWwXw0RO_R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}